From 5171876c7cb42c110d89b1aebf8030aa7a4bb74a Mon Sep 17 00:00:00 2001
From: Mika Laitio <lamikr@gmail.com>
Date: Wed, 26 Jun 2024 14:44:04 -0700
Subject: [PATCH 3/6] allow building deepspeed for rocm in virtual linux

enable the deepspeed rocm build on virtual linux env
without access to real GPU. (gpu list is also passed as a parameter)

fixes: https://github.com/lamikr/rocm_sdk_builder/issues/75

Signed-off-by: Mika Laitio <lamikr@gmail.com>
---
 build_rocm.sh         | 4 +++-
 op_builder/builder.py | 2 +-
 setup.py              | 2 +-
 3 files changed, 5 insertions(+), 3 deletions(-)

diff --git a/build_rocm.sh b/build_rocm.sh
index f4a75855..b48a0ad9 100755
--- a/build_rocm.sh
+++ b/build_rocm.sh
@@ -15,7 +15,9 @@ mkdir -p deepspeed/ops/spatial
 #export CFLAGS="-I/usr/include"
 #export LDFLAGS="-L/usr/lib64"
 
+# needed by real accelerator.py to detect the cuda when build on virtual linux without access to real hardware
+export DS_ACCELERATOR=cuda
 # install command will create wheel and install it. bdist_wheel comamnd would only create the wheel
-AMDGPU_TARGETS=${amd_target_gpu} DS_BUILD_AIO=0 DS_BUILD_FP_QUANTIZER=0 DS_BUILD_QUANTIZER=0 DS_BUILD_SPARSE_ATTN=0 DS_BUILD_RAGGED_DEVICE_OPS=0 DS_BUILD_CUTLASS_OPS=0 DS_BUILD_EVOFORMER_ATTN=0 DS_BUILD_OPS=1 python setup.py bdist_wheel
+AMDGPU_TARGETS="${amd_target_gpu}" DS_BUILD_AIO=0 DS_BUILD_FP_QUANTIZER=0 DS_BUILD_QUANTIZER=0 DS_BUILD_SPARSE_ATTN=0 DS_BUILD_RAGGED_DEVICE_OPS=0 DS_BUILD_CUTLASS_OPS=0 DS_BUILD_EVOFORMER_ATTN=0 DS_BUILD_OPS=1 python setup.py bdist_wheel
 
 #DS_BUILD_UTILS=1 DS_BUILD_CPU_ADAGRAD=1 DS_BUILD_RANDOM_LTD=1 DS_BUILD_CPU_ADAM=1 DS_BUILD_FUSED_ADAM=1 DS_BUILD_FUSED_LAMB=1 DS_BUILD_CCL_COMM=1 python setup.py develop
diff --git a/op_builder/builder.py b/op_builder/builder.py
index 208ec454..7de197cc 100644
--- a/op_builder/builder.py
+++ b/op_builder/builder.py
@@ -539,7 +539,7 @@ class OpBuilder(ABC):
             # Ensure the op we're about to load was compiled with the same
             # torch/cuda versions we are currently using at runtime.
             self.validate_torch_version(torch_info)
-            if torch.cuda.is_available() and isinstance(self, CUDAOpBuilder):
+            if (self.is_rocm_pytorch() or torch.cuda.is_available()) and isinstance(self, CUDAOpBuilder):
                 self.validate_torch_op_version(torch_info)
 
             op_module = importlib.import_module(self.absolute_name())
diff --git a/setup.py b/setup.py
index 5b8a917d..973f2610 100755
--- a/setup.py
+++ b/setup.py
@@ -136,7 +136,7 @@ else:
     TORCH_MAJOR = "0"
     TORCH_MINOR = "0"
 
-if torch_available and not get_accelerator().device_name() == 'cuda':
+if torch_available and not is_rocm_pytorch and not get_accelerator().device_name() == 'cuda':
     # Fix to allow docker builds, similar to https://github.com/NVIDIA/apex/issues/486.
     print("[WARNING] Torch did not find cuda available, if cross-compiling or running with cpu only "
           "you can ignore this message. Adding compute capability for Pascal, Volta, and Turing "
-- 
2.34.1

